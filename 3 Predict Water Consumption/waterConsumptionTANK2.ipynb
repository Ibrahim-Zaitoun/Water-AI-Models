{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T21:11:29.871518Z","iopub.execute_input":"2023-09-01T21:11:29.871904Z","iopub.status.idle":"2023-09-01T21:11:30.328927Z","shell.execute_reply.started":"2023-09-01T21:11:29.871870Z","shell.execute_reply":"2023-09-01T21:11:30.328042Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/water-consumption/Household water consumption dataset/Data Description/Tank 2-Data Description.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Data Description/Tank 1-Data Description.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/3.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/9.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/4.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/12.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/14.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/1.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/7.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/11.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/8.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/16.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/10.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/13.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/2.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/5.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/6.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files/15.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/3.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/9.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/4.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/12.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/1.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/7.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/11.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/8.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/10.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/13.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/2.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/5.xlsx\n/kaggle/input/water-consumption/Household water consumption dataset/Tank 1-Data Files/6.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import LSTM, Dense, GRU\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:30.330581Z","iopub.execute_input":"2023-09-01T21:11:30.332029Z","iopub.status.idle":"2023-09-01T21:11:41.373886Z","shell.execute_reply.started":"2023-09-01T21:11:30.331959Z","shell.execute_reply":"2023-09-01T21:11:41.372490Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/water-consumption/Household water consumption dataset/Tank 2-Data Files'\nfiles_list = glob.glob(folder_path + '/*.xlsx')\ndfs = []\nfor file in files_list:\n    df = pd.read_excel(file, parse_dates=(['created_at']))\n    dfs.append(df)\n    \nmerged_df = pd.concat(dfs, ignore_index=True)\nmerged_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:41.375447Z","iopub.execute_input":"2023-09-01T21:11:41.376473Z","iopub.status.idle":"2023-09-01T21:11:57.809389Z","shell.execute_reply.started":"2023-09-01T21:11:41.376415Z","shell.execute_reply":"2023-09-01T21:11:57.808018Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"           created_at  entry_id  field1\n0 2018-02-02 04:59:00     17392    25.0\n1 2018-02-02 04:59:19     17393    25.0\n2 2018-02-02 04:59:38     17394    25.0\n3 2018-02-02 04:59:58     17395    25.0\n4 2018-02-02 05:00:17     17396    25.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>entry_id</th>\n      <th>field1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-02-02 04:59:00</td>\n      <td>17392</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-02-02 04:59:19</td>\n      <td>17393</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-02-02 04:59:38</td>\n      <td>17394</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-02-02 04:59:58</td>\n      <td>17395</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-02-02 05:00:17</td>\n      <td>17396</td>\n      <td>25.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"merged_df['created_at'] = pd.to_datetime(merged_df['created_at'], format='%d/%m/%Y %H:%M')\nmerged_df[\"year\"] = merged_df[\"created_at\"].dt.year\nmerged_df[\"month\"] = merged_df[\"created_at\"].dt.month\nmerged_df[\"day\"] = merged_df[\"created_at\"].dt.day\nmerged_df[\"hour\"] = merged_df[\"created_at\"].dt.hour\nmerged_df[\"minute\"] = merged_df[\"created_at\"].dt.minute\nmerged_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:57.812249Z","iopub.execute_input":"2023-09-01T21:11:57.812913Z","iopub.status.idle":"2023-09-01T21:11:57.931974Z","shell.execute_reply.started":"2023-09-01T21:11:57.812877Z","shell.execute_reply":"2023-09-01T21:11:57.930889Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           created_at  entry_id  field1  year  month  day  hour  minute\n0 2018-02-02 04:59:00     17392    25.0  2018      2    2     4      59\n1 2018-02-02 04:59:19     17393    25.0  2018      2    2     4      59\n2 2018-02-02 04:59:38     17394    25.0  2018      2    2     4      59\n3 2018-02-02 04:59:58     17395    25.0  2018      2    2     4      59\n4 2018-02-02 05:00:17     17396    25.0  2018      2    2     5       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>entry_id</th>\n      <th>field1</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-02-02 04:59:00</td>\n      <td>17392</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-02-02 04:59:19</td>\n      <td>17393</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-02-02 04:59:38</td>\n      <td>17394</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-02-02 04:59:58</td>\n      <td>17395</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-02-02 05:00:17</td>\n      <td>17396</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"null_data = merged_df.isna().sum()\nduplicate_rows = merged_df.duplicated()\nprint('Nulls', null_data)\nprint('Duplicates', duplicate_rows)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:57.933798Z","iopub.execute_input":"2023-09-01T21:11:57.934278Z","iopub.status.idle":"2023-09-01T21:11:57.999391Z","shell.execute_reply.started":"2023-09-01T21:11:57.934238Z","shell.execute_reply":"2023-09-01T21:11:57.998220Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Nulls created_at    0\nentry_id      0\nfield1        0\nyear          0\nmonth         0\nday           0\nhour          0\nminute        0\ndtype: int64\nDuplicates 0         False\n1         False\n2         False\n3         False\n4         False\n          ...  \n171692    False\n171693    False\n171694    False\n171695    False\n171696    False\nLength: 171697, dtype: bool\n","output_type":"stream"}]},{"cell_type":"code","source":"# Detecting outliers using Z-score or IQR\n# Let's focus on the \"field1\" column for outlier detection\nQ1 = merged_df[\"field1\"].quantile(0.25)\nQ3 = merged_df[\"field1\"].quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n\n# Identify and remove outliers\ndf_no_outliers = merged_df[\n    (merged_df[\"field1\"].iloc[:] >= lower_bound) &\n    (merged_df[\"field1\"].iloc[:] <= upper_bound)\n]\ndf_no_outliers.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:58.000756Z","iopub.execute_input":"2023-09-01T21:11:58.002158Z","iopub.status.idle":"2023-09-01T21:11:58.042517Z","shell.execute_reply.started":"2023-09-01T21:11:58.002104Z","shell.execute_reply":"2023-09-01T21:11:58.041332Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           created_at  entry_id  field1  year  month  day  hour  minute\n0 2018-02-02 04:59:00     17392    25.0  2018      2    2     4      59\n1 2018-02-02 04:59:19     17393    25.0  2018      2    2     4      59\n2 2018-02-02 04:59:38     17394    25.0  2018      2    2     4      59\n3 2018-02-02 04:59:58     17395    25.0  2018      2    2     4      59\n4 2018-02-02 05:00:17     17396    25.0  2018      2    2     5       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>entry_id</th>\n      <th>field1</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-02-02 04:59:00</td>\n      <td>17392</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-02-02 04:59:19</td>\n      <td>17393</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-02-02 04:59:38</td>\n      <td>17394</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-02-02 04:59:58</td>\n      <td>17395</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-02-02 05:00:17</td>\n      <td>17396</td>\n      <td>25.0</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df_no_outliers.drop(['field1', 'created_at'], axis=1)\ny = df_no_outliers['field1']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:58.044144Z","iopub.execute_input":"2023-09-01T21:11:58.044496Z","iopub.status.idle":"2023-09-01T21:11:58.094526Z","shell.execute_reply.started":"2023-09-01T21:11:58.044448Z","shell.execute_reply":"2023-09-01T21:11:58.093064Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Applying Standard Scaling to the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:58.096158Z","iopub.execute_input":"2023-09-01T21:11:58.096546Z","iopub.status.idle":"2023-09-01T21:11:58.131569Z","shell.execute_reply.started":"2023-09-01T21:11:58.096511Z","shell.execute_reply":"2023-09-01T21:11:58.130318Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Reshape data for LSTM and  gru (samples, timesteps, features)\nX_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\nX_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:58.132614Z","iopub.execute_input":"2023-09-01T21:11:58.132938Z","iopub.status.idle":"2023-09-01T21:11:58.138787Z","shell.execute_reply.started":"2023-09-01T21:11:58.132911Z","shell.execute_reply":"2023-09-01T21:11:58.137958Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# lstm_model = Sequential([\n#     LSTM(128, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True),\n#     LSTM(64, activation='relu'),\n#     Dense(1)  # Output layer\n# ])\n\n# lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n\n# # Use early stopping to prevent overfitting\n# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# lstm_model.fit(X_train_reshaped, y_train, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n\n# # Evaluate the LSTM model\n# y_pred_lstm = lstm_model.predict(X_test_reshaped)\n\n# # Calculate and print R-squared\n# r_squared_lstm = r2_score(y_test, y_pred_lstm)\n# print(\"LSTM R-squared:\", r_squared_lstm)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:11:58.141748Z","iopub.execute_input":"2023-09-01T21:11:58.142498Z","iopub.status.idle":"2023-09-01T21:23:01.965620Z","shell.execute_reply.started":"2023-09-01T21:11:58.142466Z","shell.execute_reply":"2023-09-01T21:23:01.964449Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/50\n3347/3347 [==============================] - 19s 5ms/step - loss: 357.4482 - val_loss: 291.9199\nEpoch 2/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 286.0229 - val_loss: 278.9136\nEpoch 3/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 248.6742 - val_loss: 221.1562\nEpoch 4/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 210.2983 - val_loss: 199.7903\nEpoch 5/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 190.2350 - val_loss: 178.8681\nEpoch 6/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 165.5320 - val_loss: 150.8909\nEpoch 7/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 126.5430 - val_loss: 104.3700\nEpoch 8/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 81.9238 - val_loss: 58.6855\nEpoch 9/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 53.1956 - val_loss: 45.3628\nEpoch 10/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 43.0812 - val_loss: 39.3301\nEpoch 11/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 38.3359 - val_loss: 37.1346\nEpoch 12/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 35.0474 - val_loss: 30.7769\nEpoch 13/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 32.6858 - val_loss: 29.5028\nEpoch 14/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 30.8378 - val_loss: 29.2829\nEpoch 15/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 29.2524 - val_loss: 27.4278\nEpoch 16/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 27.3862 - val_loss: 34.5210\nEpoch 17/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 24.9938 - val_loss: 23.4482\nEpoch 18/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 20.2065 - val_loss: 19.6360\nEpoch 19/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 16.3312 - val_loss: 17.5350\nEpoch 20/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 14.2455 - val_loss: 11.9397\nEpoch 21/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 12.7825 - val_loss: 12.3257\nEpoch 22/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 11.7772 - val_loss: 10.5193\nEpoch 23/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 10.8837 - val_loss: 13.1667\nEpoch 24/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 10.1807 - val_loss: 9.6733\nEpoch 25/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 9.5038 - val_loss: 8.6860\nEpoch 26/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 9.0138 - val_loss: 9.4325\nEpoch 27/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 8.4166 - val_loss: 9.7320\nEpoch 28/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 8.0812 - val_loss: 7.4346\nEpoch 29/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 7.6097 - val_loss: 8.3549\nEpoch 30/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 7.3895 - val_loss: 6.4046\nEpoch 31/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 7.0999 - val_loss: 7.3181\nEpoch 32/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 6.7585 - val_loss: 7.3970\nEpoch 33/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 6.6385 - val_loss: 6.2539\nEpoch 34/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 6.4482 - val_loss: 6.1457\nEpoch 35/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 6.1521 - val_loss: 5.3992\nEpoch 36/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 6.0762 - val_loss: 4.8580\nEpoch 37/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 5.7795 - val_loss: 8.7651\nEpoch 38/50\n3347/3347 [==============================] - 16s 5ms/step - loss: 5.8933 - val_loss: 6.8084\nEpoch 39/50\n3347/3347 [==============================] - 17s 5ms/step - loss: 5.5761 - val_loss: 5.2329\nEpoch 40/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 5.4454 - val_loss: 5.2009\nEpoch 41/50\n3347/3347 [==============================] - 15s 5ms/step - loss: 5.3615 - val_loss: 5.3004\n1046/1046 [==============================] - 2s 2ms/step\nLSTM R-squared: 0.9840452769267113\n","output_type":"stream"}]},{"cell_type":"code","source":"# r_squared = r2_score(y_test, y_pred_lstm)\n# mae = mean_absolute_error(y_test, y_pred_lstm)\n# rmse = mean_squared_error(y_test, y_pred_lstm, squared=False)\n# mse = mean_squared_error(y_test, y_pred_lstm)\n\n# print(\"TANK1:\")\n# print(\"R-squared:\", r_squared)\n# print(\"Mean Absolute Error:\", mae)\n# print(\"Root Mean Squared Error:\", rmse)\n# print(\"Mean Squared Error:\", mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:25:34.765358Z","iopub.execute_input":"2023-09-01T21:25:34.765833Z","iopub.status.idle":"2023-09-01T21:25:34.778086Z","shell.execute_reply.started":"2023-09-01T21:25:34.765778Z","shell.execute_reply":"2023-09-01T21:25:34.776896Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"TANK1:\nR-squared: 0.9840452769267113\nMean Absolute Error: 1.2630302629077226\nRoot Mean Squared Error: 2.354017631846011\nMean Squared Error: 5.541399011041902\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch\nimport kerastuner as kt\n\n# Define a function to build the LSTM model with hyperparameters\ndef build_model(hp):\n    model = keras.Sequential()\n    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32),\n                   activation=hp.Choice('activation', values=['relu', 'tanh']),\n                   return_sequences=True,\n                   input_shape=(1, X_train_scaled.shape[1])))\n    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32),\n                   activation=hp.Choice('activation', values=['relu', 'tanh'])))\n    model.add(Dense(1))\n\n    # Compile the model\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n                  loss='mse',\n                  metrics=['mse'])\n    return model\n\n# Define the tuner and search space\ntuner = RandomSearch(\n    build_model,\n    objective='val_loss',\n    max_trials=10,  # Number of trials to run\n    directory='my_tuning_directory',  # Directory to save results\n    project_name='my_lstm_tuning'  # Name for this tuning project\n)\n\n# Perform hyperparameter tuning\ntuner.search(X_train_reshaped, y_train, epochs=50, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n\n# Get the best hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# Build the best model\nbest_model = tuner.hypermodel.build(best_hps)\n\n# Train the best model\nbest_model.fit(X_train_reshaped, y_train, epochs=100, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n\n# Evaluate the best model\ny_pred = best_model.predict(X_test_reshaped)\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error (MSE) for Best Model:\", mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T21:57:17.552566Z","iopub.execute_input":"2023-09-01T21:57:17.553488Z","iopub.status.idle":"2023-09-02T02:16:25.747178Z","shell.execute_reply.started":"2023-09-01T21:57:17.553454Z","shell.execute_reply":"2023-09-02T02:16:25.746039Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 14m 57s]\nval_loss: 3.524121046066284\n\nBest val_loss So Far: 2.0956525802612305\nTotal elapsed time: 03h 53m 00s\nEpoch 1/100\n4183/4183 [==============================] - 39s 8ms/step - loss: 341.1127 - mse: 341.1127 - val_loss: 295.5520 - val_mse: 295.5520\nEpoch 2/100\n4183/4183 [==============================] - 33s 8ms/step - loss: 282.7931 - mse: 282.7931 - val_loss: 271.7599 - val_mse: 271.7599\nEpoch 3/100\n4183/4183 [==============================] - 31s 8ms/step - loss: 226.6319 - mse: 226.6319 - val_loss: 190.4625 - val_mse: 190.4625\nEpoch 4/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 156.4347 - mse: 156.4347 - val_loss: 130.0904 - val_mse: 130.0904\nEpoch 5/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 103.3890 - mse: 103.3890 - val_loss: 81.8784 - val_mse: 81.8784\nEpoch 6/100\n4183/4183 [==============================] - 31s 7ms/step - loss: 69.0744 - mse: 69.0744 - val_loss: 56.3356 - val_mse: 56.3356\nEpoch 7/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 50.0500 - mse: 50.0500 - val_loss: 43.4108 - val_mse: 43.4108\nEpoch 8/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 40.5001 - mse: 40.5001 - val_loss: 36.7765 - val_mse: 36.7765\nEpoch 9/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 34.6039 - mse: 34.6039 - val_loss: 31.9054 - val_mse: 31.9054\nEpoch 10/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 29.9950 - mse: 29.9950 - val_loss: 28.4481 - val_mse: 28.4481\nEpoch 11/100\n4183/4183 [==============================] - 31s 7ms/step - loss: 26.3092 - mse: 26.3092 - val_loss: 25.0700 - val_mse: 25.0700\nEpoch 12/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 21.8773 - mse: 21.8773 - val_loss: 20.4737 - val_mse: 20.4737\nEpoch 13/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 18.4130 - mse: 18.4130 - val_loss: 16.4317 - val_mse: 16.4317\nEpoch 14/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 14.6888 - mse: 14.6888 - val_loss: 12.6955 - val_mse: 12.6955\nEpoch 15/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 11.5882 - mse: 11.5882 - val_loss: 11.2608 - val_mse: 11.2608\nEpoch 16/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 9.7509 - mse: 9.7509 - val_loss: 9.4471 - val_mse: 9.4471\nEpoch 17/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 7.9834 - mse: 7.9834 - val_loss: 8.5634 - val_mse: 8.5634\nEpoch 18/100\n4183/4183 [==============================] - 33s 8ms/step - loss: 6.5314 - mse: 6.5314 - val_loss: 5.5925 - val_mse: 5.5925\nEpoch 19/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 5.4957 - mse: 5.4957 - val_loss: 5.2989 - val_mse: 5.2989\nEpoch 20/100\n4183/4183 [==============================] - 33s 8ms/step - loss: 4.8852 - mse: 4.8852 - val_loss: 5.1027 - val_mse: 5.1027\nEpoch 21/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 4.6666 - mse: 4.6666 - val_loss: 5.0626 - val_mse: 5.0626\nEpoch 22/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 4.4500 - mse: 4.4500 - val_loss: 4.5829 - val_mse: 4.5829\nEpoch 23/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 4.0573 - mse: 4.0573 - val_loss: 4.1814 - val_mse: 4.1814\nEpoch 24/100\n4183/4183 [==============================] - 33s 8ms/step - loss: 4.0413 - mse: 4.0413 - val_loss: 4.0294 - val_mse: 4.0294\nEpoch 25/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 3.7902 - mse: 3.7902 - val_loss: 4.9113 - val_mse: 4.9113\nEpoch 26/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 3.8012 - mse: 3.8012 - val_loss: 3.6112 - val_mse: 3.6112\nEpoch 27/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 3.6313 - mse: 3.6313 - val_loss: 3.8566 - val_mse: 3.8566\nEpoch 28/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 3.4549 - mse: 3.4549 - val_loss: 3.2927 - val_mse: 3.2927\nEpoch 29/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 3.3999 - mse: 3.3999 - val_loss: 3.3227 - val_mse: 3.3227\nEpoch 30/100\n4183/4183 [==============================] - 31s 8ms/step - loss: 3.1641 - mse: 3.1641 - val_loss: 3.2648 - val_mse: 3.2648\nEpoch 31/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 3.2007 - mse: 3.2007 - val_loss: 3.6420 - val_mse: 3.6420\nEpoch 32/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 3.0972 - mse: 3.0972 - val_loss: 3.2103 - val_mse: 3.2103\nEpoch 33/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 3.0337 - mse: 3.0337 - val_loss: 3.1341 - val_mse: 3.1341\nEpoch 34/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 2.9689 - mse: 2.9689 - val_loss: 3.0129 - val_mse: 3.0129\nEpoch 35/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 2.9510 - mse: 2.9510 - val_loss: 2.7780 - val_mse: 2.7780\nEpoch 36/100\n4183/4183 [==============================] - 32s 8ms/step - loss: 2.8621 - mse: 2.8621 - val_loss: 3.4867 - val_mse: 3.4867\nEpoch 37/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 2.6819 - mse: 2.6819 - val_loss: 2.8938 - val_mse: 2.8938\nEpoch 38/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.7601 - mse: 2.7601 - val_loss: 2.6611 - val_mse: 2.6611\nEpoch 39/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.7538 - mse: 2.7538 - val_loss: 4.3407 - val_mse: 4.3407\nEpoch 40/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.6496 - mse: 2.6496 - val_loss: 3.7201 - val_mse: 3.7201\nEpoch 41/100\n4183/4183 [==============================] - 33s 8ms/step - loss: 2.5568 - mse: 2.5568 - val_loss: 2.6651 - val_mse: 2.6651\nEpoch 42/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.5597 - mse: 2.5597 - val_loss: 2.4833 - val_mse: 2.4833\nEpoch 43/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.5128 - mse: 2.5128 - val_loss: 2.8212 - val_mse: 2.8212\nEpoch 44/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.5584 - mse: 2.5584 - val_loss: 2.6272 - val_mse: 2.6272\nEpoch 45/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 2.5331 - mse: 2.5331 - val_loss: 2.5007 - val_mse: 2.5007\nEpoch 46/100\n4183/4183 [==============================] - 34s 8ms/step - loss: 2.3595 - mse: 2.3595 - val_loss: 2.6248 - val_mse: 2.6248\nEpoch 47/100\n4183/4183 [==============================] - 35s 8ms/step - loss: 2.3799 - mse: 2.3799 - val_loss: 2.5308 - val_mse: 2.5308\n1046/1046 [==============================] - 4s 3ms/step\nMean Squared Error (MSE) for Best Model: 2.483278335045146\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\nr_squared = r2_score(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nmse = mean_squared_error(y_test, y_pred)\n\nprint(\"TANK2:\")\nprint(\"R-squared:\", r_squared)\nprint(\"Mean Absolute Error:\", mae)\nprint(\"Root Mean Squared Error:\", rmse)\nprint(\"Mean Squared Error:\", mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T02:16:25.749516Z","iopub.execute_input":"2023-09-02T02:16:25.749875Z","iopub.status.idle":"2023-09-02T02:16:25.760703Z","shell.execute_reply.started":"2023-09-02T02:16:25.749844Z","shell.execute_reply":"2023-09-02T02:16:25.759583Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"TANK2:\nR-squared: 0.9928501777131379\nMean Absolute Error: 0.6301422638430128\nRoot Mean Squared Error: 1.5758421034625094\nMean Squared Error: 2.483278335045146\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}