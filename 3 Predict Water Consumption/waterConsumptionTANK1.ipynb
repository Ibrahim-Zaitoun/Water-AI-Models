{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>field1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-14 04:50:55</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-14 04:51:33</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-14 04:52:12</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-14 04:52:51</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-14 04:53:30</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  entry_id  field1\n",
       "0 2018-02-14 04:50:55         1      40\n",
       "1 2018-02-14 04:51:33         2      39\n",
       "2 2018-02-14 04:52:12         3      40\n",
       "3 2018-02-14 04:52:51         4      40\n",
       "4 2018-02-14 04:53:30         5      40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = './Tank1'\n",
    "\n",
    "file_list = glob.glob(folder_path + '/*.xlsx')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.read_excel(file, parse_dates=['created_at'])\n",
    "    dfs.append(df)\n",
    "    \n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>field1</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-14 04:50:55</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-14 04:51:33</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-14 04:52:12</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-14 04:52:51</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-14 04:53:30</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  entry_id  field1  year  month  day  hour  minute\n",
       "0 2018-02-14 04:50:55         1      40  2018      2   14     4      50\n",
       "1 2018-02-14 04:51:33         2      39  2018      2   14     4      51\n",
       "2 2018-02-14 04:52:12         3      40  2018      2   14     4      52\n",
       "3 2018-02-14 04:52:51         4      40  2018      2   14     4      52\n",
       "4 2018-02-14 04:53:30         5      40  2018      2   14     4      53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"created_at\"] = pd.to_datetime(merged_df[\"created_at\"], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "merged_df[\"year\"] = merged_df[\"created_at\"].dt.year\n",
    "merged_df[\"month\"] = merged_df[\"created_at\"].dt.month\n",
    "merged_df[\"day\"] = merged_df[\"created_at\"].dt.day\n",
    "merged_df[\"hour\"] = merged_df[\"created_at\"].dt.hour\n",
    "merged_df[\"minute\"] = merged_df[\"created_at\"].dt.minute\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls created_at    0\n",
      "entry_id      0\n",
      "field1        0\n",
      "year          0\n",
      "month         0\n",
      "day           0\n",
      "hour          0\n",
      "minute        0\n",
      "dtype: int64\n",
      "Duplicates 0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "89392    False\n",
      "89393    False\n",
      "89394    False\n",
      "89395    False\n",
      "89396    False\n",
      "Length: 89397, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "null_data = merged_df.isna().sum()\n",
    "duplicate_rows = merged_df.duplicated()\n",
    "print('Nulls', null_data)\n",
    "print('Duplicates', duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting outliers using Z-score or IQR\n",
    "# Let's focus on the \"field1\" column for outlier detection\n",
    "Q1 = merged_df[\"field1\"].quantile(0.25)\n",
    "Q3 = merged_df[\"field1\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "# Identify and remove outliers\n",
    "df_no_outliers = merged_df[\n",
    "    (merged_df[\"field1\"].iloc[:] >= lower_bound) &\n",
    "    (merged_df[\"field1\"].iloc[:] <= upper_bound)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features (X) and target (y)\n",
    "X = df_no_outliers.drop([\"field1\", \"created_at\"], axis=1)  # Features excluding \"field1\" and \"created_at\"\n",
    "y = df_no_outliers[\"field1\"]  # Target variable\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Standard Scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1788/1788 [==============================] - 2s 925us/step - loss: 466.6266 - val_loss: 198.1864\n",
      "Epoch 2/50\n",
      "1788/1788 [==============================] - 2s 950us/step - loss: 173.4232 - val_loss: 154.0256\n",
      "Epoch 3/50\n",
      "1788/1788 [==============================] - 2s 911us/step - loss: 134.8502 - val_loss: 123.0898\n",
      "Epoch 4/50\n",
      "1788/1788 [==============================] - 2s 933us/step - loss: 115.8593 - val_loss: 110.4389\n",
      "Epoch 5/50\n",
      "1788/1788 [==============================] - 2s 860us/step - loss: 103.7178 - val_loss: 98.0646\n",
      "Epoch 6/50\n",
      "1788/1788 [==============================] - 2s 854us/step - loss: 93.0317 - val_loss: 88.8301\n",
      "Epoch 7/50\n",
      "1788/1788 [==============================] - 2s 879us/step - loss: 83.7538 - val_loss: 80.5912\n",
      "Epoch 8/50\n",
      "1788/1788 [==============================] - 2s 932us/step - loss: 75.1740 - val_loss: 72.6766\n",
      "Epoch 9/50\n",
      "1788/1788 [==============================] - 2s 903us/step - loss: 68.5910 - val_loss: 67.5793\n",
      "Epoch 10/50\n",
      "1788/1788 [==============================] - 2s 880us/step - loss: 63.2166 - val_loss: 63.2848\n",
      "Epoch 11/50\n",
      "1788/1788 [==============================] - 2s 903us/step - loss: 58.3692 - val_loss: 57.2847\n",
      "Epoch 12/50\n",
      "1788/1788 [==============================] - 2s 866us/step - loss: 54.0872 - val_loss: 53.2200\n",
      "Epoch 13/50\n",
      "1788/1788 [==============================] - 2s 859us/step - loss: 50.5800 - val_loss: 51.4540\n",
      "Epoch 14/50\n",
      "1788/1788 [==============================] - 2s 859us/step - loss: 47.9861 - val_loss: 49.6027\n",
      "Epoch 15/50\n",
      "1788/1788 [==============================] - 2s 891us/step - loss: 45.8166 - val_loss: 47.1663\n",
      "Epoch 16/50\n",
      "1788/1788 [==============================] - 2s 843us/step - loss: 44.3330 - val_loss: 45.2320\n",
      "Epoch 17/50\n",
      "1788/1788 [==============================] - 2s 897us/step - loss: 42.8159 - val_loss: 45.6484\n",
      "Epoch 18/50\n",
      "1788/1788 [==============================] - 2s 856us/step - loss: 41.9355 - val_loss: 42.3094\n",
      "Epoch 19/50\n",
      "1788/1788 [==============================] - 2s 865us/step - loss: 40.9712 - val_loss: 44.0058\n",
      "Epoch 20/50\n",
      "1788/1788 [==============================] - 2s 850us/step - loss: 40.1922 - val_loss: 40.6386\n",
      "Epoch 21/50\n",
      "1788/1788 [==============================] - 2s 842us/step - loss: 39.1584 - val_loss: 39.7270\n",
      "Epoch 22/50\n",
      "1788/1788 [==============================] - 2s 846us/step - loss: 38.4960 - val_loss: 38.4921\n",
      "Epoch 23/50\n",
      "1788/1788 [==============================] - 2s 878us/step - loss: 37.9659 - val_loss: 38.8277\n",
      "Epoch 24/50\n",
      "1788/1788 [==============================] - 2s 910us/step - loss: 37.3751 - val_loss: 38.8839\n",
      "Epoch 25/50\n",
      "1788/1788 [==============================] - 2s 850us/step - loss: 36.6864 - val_loss: 38.4570\n",
      "Epoch 26/50\n",
      "1788/1788 [==============================] - 2s 856us/step - loss: 36.3882 - val_loss: 40.1453\n",
      "Epoch 27/50\n",
      "1788/1788 [==============================] - 2s 891us/step - loss: 35.7305 - val_loss: 36.5656\n",
      "Epoch 28/50\n",
      "1788/1788 [==============================] - 2s 908us/step - loss: 35.4420 - val_loss: 36.2073\n",
      "Epoch 29/50\n",
      "1788/1788 [==============================] - 2s 861us/step - loss: 35.0599 - val_loss: 35.4158\n",
      "Epoch 30/50\n",
      "1788/1788 [==============================] - 2s 894us/step - loss: 34.9202 - val_loss: 37.5351\n",
      "Epoch 31/50\n",
      "1788/1788 [==============================] - 2s 864us/step - loss: 34.6479 - val_loss: 38.5537\n",
      "Epoch 32/50\n",
      "1788/1788 [==============================] - 2s 851us/step - loss: 34.2740 - val_loss: 35.2735\n",
      "Epoch 33/50\n",
      "1788/1788 [==============================] - 2s 868us/step - loss: 34.1009 - val_loss: 35.8933\n",
      "Epoch 34/50\n",
      "1788/1788 [==============================] - 2s 873us/step - loss: 33.7877 - val_loss: 34.3229\n",
      "Epoch 35/50\n",
      "1788/1788 [==============================] - 2s 848us/step - loss: 33.5179 - val_loss: 34.9016\n",
      "Epoch 36/50\n",
      "1788/1788 [==============================] - 2s 867us/step - loss: 33.5042 - val_loss: 34.6422\n",
      "Epoch 37/50\n",
      "1788/1788 [==============================] - 2s 924us/step - loss: 33.0344 - val_loss: 34.7302\n",
      "Epoch 38/50\n",
      "1788/1788 [==============================] - 2s 891us/step - loss: 32.8288 - val_loss: 34.0308\n",
      "Epoch 39/50\n",
      "1788/1788 [==============================] - 2s 857us/step - loss: 32.6249 - val_loss: 33.9615\n",
      "Epoch 40/50\n",
      "1788/1788 [==============================] - 1s 836us/step - loss: 32.5880 - val_loss: 32.7018\n",
      "Epoch 41/50\n",
      "1788/1788 [==============================] - 1s 837us/step - loss: 32.2812 - val_loss: 32.4806\n",
      "Epoch 42/50\n",
      "1788/1788 [==============================] - 1s 832us/step - loss: 31.9712 - val_loss: 34.1323\n",
      "Epoch 43/50\n",
      "1788/1788 [==============================] - 2s 893us/step - loss: 31.9235 - val_loss: 33.9381\n",
      "Epoch 44/50\n",
      "1788/1788 [==============================] - 2s 852us/step - loss: 31.1093 - val_loss: 32.9676\n",
      "Epoch 45/50\n",
      "1788/1788 [==============================] - 2s 847us/step - loss: 30.9262 - val_loss: 32.4961\n",
      "Epoch 46/50\n",
      "1788/1788 [==============================] - 2s 844us/step - loss: 30.5450 - val_loss: 32.6742\n",
      "Epoch 47/50\n",
      "1788/1788 [==============================] - 2s 854us/step - loss: 29.5800 - val_loss: 32.3959\n",
      "Epoch 48/50\n",
      "1788/1788 [==============================] - 2s 883us/step - loss: 29.1258 - val_loss: 29.5217\n",
      "Epoch 49/50\n",
      "1788/1788 [==============================] - 2s 871us/step - loss: 28.8967 - val_loss: 29.2232\n",
      "Epoch 50/50\n",
      "1788/1788 [==============================] - 2s 920us/step - loss: 28.4154 - val_loss: 28.4642\n",
      "559/559 [==============================] - 0s 536us/step\n",
      "Mean Squared Error: 28.44098578558015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Build a Deep Neural Network (DNN) model using Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    layers.Dense(64, activation='relu'),  # Hidden layer with 64 neurons and ReLU activation\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer with 32 neurons and ReLU activation\n",
    "    layers.Dense(1)  # Output layer (single neuron)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1788/1788 [==============================] - 2s 940us/step - loss: 473.0208 - val_loss: 211.4472\n",
      "Epoch 2/50\n",
      "1788/1788 [==============================] - 1s 821us/step - loss: 179.3819 - val_loss: 161.9510\n",
      "Epoch 3/50\n",
      "1788/1788 [==============================] - 1s 818us/step - loss: 152.4178 - val_loss: 145.0368\n",
      "Epoch 4/50\n",
      "1788/1788 [==============================] - 1s 821us/step - loss: 134.7776 - val_loss: 126.5699\n",
      "Epoch 5/50\n",
      "1788/1788 [==============================] - 2s 858us/step - loss: 117.0270 - val_loss: 114.6375\n",
      "Epoch 6/50\n",
      "1788/1788 [==============================] - 2s 836us/step - loss: 102.6768 - val_loss: 96.5255\n",
      "Epoch 7/50\n",
      "1788/1788 [==============================] - 1s 833us/step - loss: 89.6590 - val_loss: 85.5621\n",
      "Epoch 8/50\n",
      "1788/1788 [==============================] - 1s 819us/step - loss: 79.6792 - val_loss: 78.0141\n",
      "Epoch 9/50\n",
      "1788/1788 [==============================] - 1s 829us/step - loss: 72.3278 - val_loss: 72.0016\n",
      "Epoch 10/50\n",
      "1788/1788 [==============================] - 1s 825us/step - loss: 66.4161 - val_loss: 67.0851\n",
      "Epoch 11/50\n",
      "1788/1788 [==============================] - 1s 830us/step - loss: 62.2231 - val_loss: 62.4332\n",
      "Epoch 12/50\n",
      "1788/1788 [==============================] - 2s 871us/step - loss: 59.0418 - val_loss: 59.8418\n",
      "Epoch 13/50\n",
      "1788/1788 [==============================] - 2s 843us/step - loss: 56.7699 - val_loss: 61.6435\n",
      "Epoch 14/50\n",
      "1788/1788 [==============================] - 1s 838us/step - loss: 54.9467 - val_loss: 58.1599\n",
      "Epoch 15/50\n",
      "1788/1788 [==============================] - 1s 809us/step - loss: 53.8794 - val_loss: 56.5009\n",
      "Epoch 16/50\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 52.7805 - val_loss: 55.5531\n",
      "Epoch 17/50\n",
      "1788/1788 [==============================] - 1s 815us/step - loss: 52.0360 - val_loss: 54.6534\n",
      "Epoch 18/50\n",
      "1788/1788 [==============================] - 1s 822us/step - loss: 50.9376 - val_loss: 53.2976\n",
      "Epoch 19/50\n",
      "1788/1788 [==============================] - 2s 907us/step - loss: 50.1034 - val_loss: 53.0600\n",
      "Epoch 20/50\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 49.2939 - val_loss: 52.9214\n",
      "Epoch 21/50\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 48.4272 - val_loss: 50.5627\n",
      "Epoch 22/50\n",
      "1788/1788 [==============================] - 1s 828us/step - loss: 47.8103 - val_loss: 51.2319\n",
      "Epoch 23/50\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 47.2589 - val_loss: 50.7082\n",
      "Epoch 24/50\n",
      "1788/1788 [==============================] - 1s 829us/step - loss: 46.7860 - val_loss: 49.1613\n",
      "Epoch 25/50\n",
      "1788/1788 [==============================] - 1s 822us/step - loss: 46.2297 - val_loss: 49.5767\n",
      "Epoch 26/50\n",
      "1788/1788 [==============================] - 2s 862us/step - loss: 45.5596 - val_loss: 49.3917\n",
      "Epoch 27/50\n",
      "1788/1788 [==============================] - 1s 818us/step - loss: 45.0820 - val_loss: 47.7289\n",
      "Epoch 28/50\n",
      "1788/1788 [==============================] - 1s 826us/step - loss: 44.5013 - val_loss: 46.9373\n",
      "Epoch 29/50\n",
      "1788/1788 [==============================] - 2s 865us/step - loss: 43.9180 - val_loss: 44.8826\n",
      "Epoch 30/50\n",
      "1788/1788 [==============================] - 2s 858us/step - loss: 43.1954 - val_loss: 45.5314\n",
      "Epoch 31/50\n",
      "1788/1788 [==============================] - 1s 835us/step - loss: 42.7572 - val_loss: 45.0509\n",
      "Epoch 32/50\n",
      "1788/1788 [==============================] - 2s 883us/step - loss: 42.0934 - val_loss: 45.2436\n",
      "Epoch 33/50\n",
      "1788/1788 [==============================] - 2s 842us/step - loss: 41.5027 - val_loss: 42.9718\n",
      "Epoch 34/50\n",
      "1788/1788 [==============================] - 2s 842us/step - loss: 41.2086 - val_loss: 43.8180\n",
      "Epoch 35/50\n",
      "1788/1788 [==============================] - 1s 822us/step - loss: 40.7088 - val_loss: 42.6920\n",
      "Epoch 36/50\n",
      "1788/1788 [==============================] - 1s 830us/step - loss: 40.3974 - val_loss: 42.9074\n",
      "Epoch 37/50\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 40.0983 - val_loss: 41.9766\n",
      "Epoch 38/50\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 39.6596 - val_loss: 40.7751\n",
      "Epoch 39/50\n",
      "1788/1788 [==============================] - 2s 873us/step - loss: 39.5513 - val_loss: 40.5140\n",
      "Epoch 40/50\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 39.0342 - val_loss: 40.2390\n",
      "Epoch 41/50\n",
      "1788/1788 [==============================] - 1s 814us/step - loss: 38.8163 - val_loss: 41.1482\n",
      "Epoch 42/50\n",
      "1788/1788 [==============================] - 1s 825us/step - loss: 38.6286 - val_loss: 39.5831\n",
      "Epoch 43/50\n",
      "1788/1788 [==============================] - 2s 848us/step - loss: 38.5312 - val_loss: 40.1560\n",
      "Epoch 44/50\n",
      "1788/1788 [==============================] - 2s 840us/step - loss: 38.0817 - val_loss: 44.8582\n",
      "Epoch 45/50\n",
      "1788/1788 [==============================] - 1s 830us/step - loss: 37.9657 - val_loss: 41.2030\n",
      "Epoch 46/50\n",
      "1788/1788 [==============================] - 2s 888us/step - loss: 37.8517 - val_loss: 38.3505\n",
      "Epoch 47/50\n",
      "1788/1788 [==============================] - 1s 817us/step - loss: 37.5072 - val_loss: 39.3760\n",
      "Epoch 48/50\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 37.1711 - val_loss: 38.2941\n",
      "Epoch 49/50\n",
      "1788/1788 [==============================] - 1s 815us/step - loss: 37.2771 - val_loss: 38.5017\n",
      "Epoch 50/50\n",
      "1788/1788 [==============================] - 1s 815us/step - loss: 37.0398 - val_loss: 37.5486\n",
      "559/559 [==============================] - 0s 565us/step\n",
      "R-squared: 0.8972136253537141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Build a Deep Neural Network (DNN) model using Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    layers.Dense(64, activation='relu'),  # Hidden layer with 64 neurons and ReLU activation\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer with 32 neurons and ReLU activation\n",
    "    layers.Dense(1)  # Output layer (single neuron)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate R-squared value\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM and  gru (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1788/1788 [==============================] - 6s 3ms/step - loss: 442.6327 - val_loss: 180.2170\n",
      "Epoch 2/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 163.0885 - val_loss: 143.0230\n",
      "Epoch 3/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 110.0673 - val_loss: 94.1435\n",
      "Epoch 4/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 80.3962 - val_loss: 73.5287\n",
      "Epoch 5/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 66.3897 - val_loss: 61.0096\n",
      "Epoch 6/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 55.2738 - val_loss: 50.5500\n",
      "Epoch 7/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 45.4119 - val_loss: 41.8408\n",
      "Epoch 8/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 39.4259 - val_loss: 36.9045\n",
      "Epoch 9/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 34.7639 - val_loss: 32.4323\n",
      "Epoch 10/50\n",
      "1788/1788 [==============================] - 4s 3ms/step - loss: 30.0131 - val_loss: 27.1364\n",
      "Epoch 11/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 26.2709 - val_loss: 26.4435\n",
      "Epoch 12/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 23.6800 - val_loss: 22.8202\n",
      "Epoch 13/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 22.1952 - val_loss: 21.0142\n",
      "Epoch 14/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 21.0773 - val_loss: 20.6867\n",
      "Epoch 15/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 19.9336 - val_loss: 22.1402\n",
      "Epoch 16/50\n",
      "1788/1788 [==============================] - 5s 3ms/step - loss: 19.1625 - val_loss: 18.1922\n",
      "Epoch 17/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 18.0968 - val_loss: 18.0107\n",
      "Epoch 18/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 17.3836 - val_loss: 16.3311\n",
      "Epoch 19/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 16.5249 - val_loss: 16.0158\n",
      "Epoch 20/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 15.8136 - val_loss: 16.5973\n",
      "Epoch 21/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 15.0419 - val_loss: 14.8446\n",
      "Epoch 22/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 14.2861 - val_loss: 13.5033\n",
      "Epoch 23/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 13.4664 - val_loss: 12.9930\n",
      "Epoch 24/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 12.4000 - val_loss: 12.4645\n",
      "Epoch 25/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 11.6647 - val_loss: 12.1020\n",
      "Epoch 26/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 10.4685 - val_loss: 9.8453\n",
      "Epoch 27/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 9.5119 - val_loss: 9.2436\n",
      "Epoch 28/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 8.4683 - val_loss: 9.0856\n",
      "Epoch 29/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 7.8144 - val_loss: 7.0641\n",
      "Epoch 30/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 7.3345 - val_loss: 7.1050\n",
      "Epoch 31/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.9657 - val_loss: 6.9640\n",
      "Epoch 32/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.5038 - val_loss: 6.7855\n",
      "Epoch 33/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.3821 - val_loss: 5.7461\n",
      "Epoch 34/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.1324 - val_loss: 5.7458\n",
      "Epoch 35/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.9554 - val_loss: 5.2730\n",
      "Epoch 36/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.7990 - val_loss: 5.8345\n",
      "Epoch 37/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.6482 - val_loss: 5.1729\n",
      "Epoch 38/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.4929 - val_loss: 5.3065\n",
      "Epoch 39/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.3378 - val_loss: 5.4201\n",
      "Epoch 40/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.0833 - val_loss: 4.7660\n",
      "Epoch 41/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.9891 - val_loss: 4.5927\n",
      "Epoch 42/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.0273 - val_loss: 4.4964\n",
      "Epoch 43/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.8223 - val_loss: 4.7899\n",
      "Epoch 44/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.6543 - val_loss: 5.3067\n",
      "Epoch 45/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.5750 - val_loss: 4.5273\n",
      "Epoch 46/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.4355 - val_loss: 4.4029\n",
      "Epoch 47/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.3887 - val_loss: 3.8279\n",
      "Epoch 48/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.0477 - val_loss: 3.6210\n",
      "Epoch 49/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 4.1317 - val_loss: 3.9250\n",
      "Epoch 50/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 3.9705 - val_loss: 3.7522\n",
      "559/559 [==============================] - 1s 1ms/step\n",
      "LSTM R-squared: 0.98998173010528\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True),\n",
    "    LSTM(64, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "r_squared_lstm = r2_score(y_test, y_pred_lstm)\n",
    "print(\"LSTM R-squared:\", r_squared_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1788/1788 [==============================] - 6s 2ms/step - loss: 369.6432 - val_loss: 191.0354\n",
      "Epoch 2/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 180.8256 - val_loss: 167.0408\n",
      "Epoch 3/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 136.5553 - val_loss: 107.8628\n",
      "Epoch 4/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 97.4095 - val_loss: 87.2535\n",
      "Epoch 5/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 75.3096 - val_loss: 62.9872\n",
      "Epoch 6/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 51.8600 - val_loss: 49.2314\n",
      "Epoch 7/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 39.4083 - val_loss: 38.5482\n",
      "Epoch 8/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 33.1845 - val_loss: 30.2704\n",
      "Epoch 9/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 28.6242 - val_loss: 27.2737\n",
      "Epoch 10/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 25.2596 - val_loss: 23.1954\n",
      "Epoch 11/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 22.6001 - val_loss: 20.2105\n",
      "Epoch 12/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 20.0878 - val_loss: 18.5792\n",
      "Epoch 13/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 18.1157 - val_loss: 17.6348\n",
      "Epoch 14/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 16.9664 - val_loss: 17.0142\n",
      "Epoch 15/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 15.9158 - val_loss: 15.1734\n",
      "Epoch 16/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 14.4665 - val_loss: 14.7245\n",
      "Epoch 17/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 13.4016 - val_loss: 11.7512\n",
      "Epoch 18/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 12.3061 - val_loss: 11.0459\n",
      "Epoch 19/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 11.0617 - val_loss: 10.1081\n",
      "Epoch 20/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 10.3120 - val_loss: 9.0456\n",
      "Epoch 21/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 9.5655 - val_loss: 8.9539\n",
      "Epoch 22/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 8.7920 - val_loss: 10.3630\n",
      "Epoch 23/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 8.2722 - val_loss: 8.8235\n",
      "Epoch 24/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 7.8534 - val_loss: 9.6466\n",
      "Epoch 25/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 7.2725 - val_loss: 8.3074\n",
      "Epoch 26/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 7.2023 - val_loss: 7.3432\n",
      "Epoch 27/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.9049 - val_loss: 6.2318\n",
      "Epoch 28/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.5983 - val_loss: 7.2177\n",
      "Epoch 29/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.2466 - val_loss: 5.2716\n",
      "Epoch 30/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 6.0506 - val_loss: 5.5306\n",
      "Epoch 31/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.8027 - val_loss: 6.3275\n",
      "Epoch 32/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.7197 - val_loss: 5.5648\n",
      "Epoch 33/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.4209 - val_loss: 6.5903\n",
      "Epoch 34/50\n",
      "1788/1788 [==============================] - 4s 2ms/step - loss: 5.4809 - val_loss: 6.5817\n",
      "559/559 [==============================] - 1s 848us/step\n",
      "GRU R-squared: 0.9858798510684932\n"
     ]
    }
   ],
   "source": [
    "# GRU Model\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "gru_model = Sequential([\n",
    "    GRU(128, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True),\n",
    "    GRU(64, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "gru_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "gru_model.fit(X_train_reshaped, y_train, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the GRU model\n",
    "y_pred_gru = gru_model.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "r_squared_gru = r2_score(y_test, y_pred_gru)\n",
    "print(\"GRU R-squared:\", r_squared_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
