{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>field1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-14 04:50:55</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-14 04:51:33</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-14 04:52:12</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-14 04:52:51</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-14 04:53:30</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  entry_id  field1\n",
       "0 2018-02-14 04:50:55         1      40\n",
       "1 2018-02-14 04:51:33         2      39\n",
       "2 2018-02-14 04:52:12         3      40\n",
       "3 2018-02-14 04:52:51         4      40\n",
       "4 2018-02-14 04:53:30         5      40"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = './Tank1'\n",
    "\n",
    "file_list = glob.glob(folder_path + '/*.xlsx')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.read_excel(file, parse_dates=['created_at'])\n",
    "    dfs.append(df)\n",
    "    \n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>field1</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-14 04:50:55</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-14 04:51:33</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-14 04:52:12</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-14 04:52:51</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-14 04:53:30</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  entry_id  field1  year  month  day  hour  minute\n",
       "0 2018-02-14 04:50:55         1      40  2018      2   14     4      50\n",
       "1 2018-02-14 04:51:33         2      39  2018      2   14     4      51\n",
       "2 2018-02-14 04:52:12         3      40  2018      2   14     4      52\n",
       "3 2018-02-14 04:52:51         4      40  2018      2   14     4      52\n",
       "4 2018-02-14 04:53:30         5      40  2018      2   14     4      53"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"created_at\"] = pd.to_datetime(merged_df[\"created_at\"], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "merged_df[\"year\"] = merged_df[\"created_at\"].dt.year\n",
    "merged_df[\"month\"] = merged_df[\"created_at\"].dt.month\n",
    "merged_df[\"day\"] = merged_df[\"created_at\"].dt.day\n",
    "merged_df[\"hour\"] = merged_df[\"created_at\"].dt.hour\n",
    "merged_df[\"minute\"] = merged_df[\"created_at\"].dt.minute\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls created_at    0\n",
      "entry_id      0\n",
      "field1        0\n",
      "year          0\n",
      "month         0\n",
      "day           0\n",
      "hour          0\n",
      "minute        0\n",
      "dtype: int64\n",
      "Duplicates 0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "89392    False\n",
      "89393    False\n",
      "89394    False\n",
      "89395    False\n",
      "89396    False\n",
      "Length: 89397, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "null_data = merged_df.isna().sum()\n",
    "duplicate_rows = merged_df.duplicated()\n",
    "print('Nulls', null_data)\n",
    "print('Duplicates', duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               created_at  entry_id  field1  year  month  day  hour  minute\n",
      "0     2018-02-14 04:50:55         1      40  2018      2   14     4      50\n",
      "1     2018-02-14 04:51:33         2      39  2018      2   14     4      51\n",
      "2     2018-02-14 04:52:12         3      40  2018      2   14     4      52\n",
      "3     2018-02-14 04:52:51         4      40  2018      2   14     4      52\n",
      "4     2018-02-14 04:53:30         5      40  2018      2   14     4      53\n",
      "...                   ...       ...     ...   ...    ...  ...   ...     ...\n",
      "89392 2018-03-21 23:57:24     67740      60  2018      3   21    23      57\n",
      "89393 2018-03-21 23:58:03     67741      60  2018      3   21    23      58\n",
      "89394 2018-03-21 23:58:41     67742      60  2018      3   21    23      58\n",
      "89395 2018-03-21 23:59:20     67743      59  2018      3   21    23      59\n",
      "89396 2018-03-21 23:59:59     67744      60  2018      3   21    23      59\n",
      "\n",
      "[89397 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate quartiles and IQR\n",
    "Q1 = merged_df[\"field1\"].quantile(0.25)\n",
    "Q3 = merged_df[\"field1\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify and remove outliers\n",
    "df_no_outliers = merged_df[\n",
    "    (merged_df[\"field1\"] >= lower_bound) &\n",
    "    (merged_df[\"field1\"] <= upper_bound)\n",
    "]\n",
    "\n",
    "# Print the DataFrame without outliers\n",
    "print(df_no_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features (X) and target (y)\n",
    "X = df_no_outliers.drop([\"field1\", \"created_at\"], axis=1)  # Features excluding \"field1\" and \"created_at\"\n",
    "y = df_no_outliers[\"field1\"]  # Target variable\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Standard Scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\mg\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\mg\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mg\\anaconda3\\lib\\site-packages (from keras-tuner) (2.27.1)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\mg\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mg\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mg\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mg\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mg\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mg\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mg\\anaconda3\\lib\\site-packages (2.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow-addons\n",
      "  Using cached tensorflow_addons-0.21.0-cp39-cp39-win_amd64.whl (729 kB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement kerastuner (from versions: none)\n",
      "ERROR: No matching distribution found for kerastuner\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tensorflow-addons kerastuner scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your LSTM model with predefined hyperparameters\n",
    "\n",
    "# X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "# X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, X_train_scaled.shape[1])))\n",
    "# model.add(LSTM(64, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "# model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# # Define early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_reshaped, y_train, epochs=50, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# y_pred = model.predict(X_test_reshaped)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your LSTM model with predefined hyperparameters\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, X_train_scaled.shape[1])))\n",
    "# model.add(LSTM(64, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "# model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# # Define early stopping\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train the model with more epochs (e.g., 100 epochs)\n",
    "# history = model.fit(X_train_reshaped, y_train, epochs=100, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# y_pred = model.predict(X_test_reshaped)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from my_tuning_directory\\my_lstm_tuning\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "2235/2235 [==============================] - 30s 12ms/step - loss: 364.1902 - mse: 364.1902 - val_loss: 247.6577 - val_mse: 247.6577\n",
      "Epoch 2/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 236.6598 - mse: 236.6598 - val_loss: 191.4661 - val_mse: 191.4661\n",
      "Epoch 3/100\n",
      "2235/2235 [==============================] - 28s 13ms/step - loss: 182.3184 - mse: 182.3184 - val_loss: 180.8147 - val_mse: 180.8147\n",
      "Epoch 4/100\n",
      "2235/2235 [==============================] - 30s 14ms/step - loss: 157.4214 - mse: 157.4214 - val_loss: 141.6537 - val_mse: 141.6537\n",
      "Epoch 5/100\n",
      "2235/2235 [==============================] - 28s 13ms/step - loss: 124.0970 - mse: 124.0970 - val_loss: 115.8176 - val_mse: 115.8176\n",
      "Epoch 6/100\n",
      "2235/2235 [==============================] - 28s 12ms/step - loss: 101.7576 - mse: 101.7576 - val_loss: 95.8240 - val_mse: 95.8240\n",
      "Epoch 7/100\n",
      "2235/2235 [==============================] - 28s 13ms/step - loss: 89.5916 - mse: 89.5916 - val_loss: 87.7209 - val_mse: 87.7209\n",
      "Epoch 8/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 83.2523 - mse: 83.2523 - val_loss: 82.3294 - val_mse: 82.3294\n",
      "Epoch 9/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 77.0275 - mse: 77.0275 - val_loss: 73.2748 - val_mse: 73.2748\n",
      "Epoch 10/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 67.0145 - mse: 67.0145 - val_loss: 71.6916 - val_mse: 71.6916\n",
      "Epoch 11/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 57.8996 - mse: 57.8996 - val_loss: 55.8864 - val_mse: 55.8864\n",
      "Epoch 12/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 51.2663 - mse: 51.2663 - val_loss: 47.3393 - val_mse: 47.3393\n",
      "Epoch 13/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 45.4131 - mse: 45.4131 - val_loss: 43.1684 - val_mse: 43.1684\n",
      "Epoch 14/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 39.4766 - mse: 39.4766 - val_loss: 31.7421 - val_mse: 31.7421\n",
      "Epoch 15/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 28.6715 - mse: 28.6715 - val_loss: 26.5951 - val_mse: 26.5951\n",
      "Epoch 16/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 23.5315 - mse: 23.5315 - val_loss: 21.0199 - val_mse: 21.0199\n",
      "Epoch 17/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 20.8543 - mse: 20.8543 - val_loss: 18.2212 - val_mse: 18.2212\n",
      "Epoch 18/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 17.5938 - mse: 17.5938 - val_loss: 16.3194 - val_mse: 16.3194\n",
      "Epoch 19/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 16.1377 - mse: 16.1377 - val_loss: 14.4228 - val_mse: 14.4228\n",
      "Epoch 20/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 14.5596 - mse: 14.5596 - val_loss: 13.5091 - val_mse: 13.5091\n",
      "Epoch 21/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 13.7183 - mse: 13.7183 - val_loss: 12.3391 - val_mse: 12.3391\n",
      "Epoch 22/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 12.6474 - mse: 12.6474 - val_loss: 11.5728 - val_mse: 11.5728\n",
      "Epoch 23/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 12.2025 - mse: 12.2025 - val_loss: 10.3377 - val_mse: 10.3377\n",
      "Epoch 24/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 11.0765 - mse: 11.0765 - val_loss: 11.0805 - val_mse: 11.0805\n",
      "Epoch 25/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 10.4219 - mse: 10.4219 - val_loss: 9.1484 - val_mse: 9.1484\n",
      "Epoch 26/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 9.9174 - mse: 9.9174 - val_loss: 8.5343 - val_mse: 8.5343\n",
      "Epoch 27/100\n",
      "2235/2235 [==============================] - 28s 12ms/step - loss: 9.1664 - mse: 9.1664 - val_loss: 7.9272 - val_mse: 7.9272\n",
      "Epoch 28/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 8.9002 - mse: 8.9002 - val_loss: 7.6520 - val_mse: 7.6520\n",
      "Epoch 29/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 8.4852 - mse: 8.4852 - val_loss: 7.2636 - val_mse: 7.2636\n",
      "Epoch 30/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 7.9707 - mse: 7.9707 - val_loss: 7.3118 - val_mse: 7.3118\n",
      "Epoch 31/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 7.6455 - mse: 7.6455 - val_loss: 7.1259 - val_mse: 7.1259\n",
      "Epoch 32/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 7.4695 - mse: 7.4695 - val_loss: 7.2753 - val_mse: 7.2753\n",
      "Epoch 33/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 7.2875 - mse: 7.2875 - val_loss: 7.2275 - val_mse: 7.2275\n",
      "Epoch 34/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 7.2497 - mse: 7.2497 - val_loss: 6.1772 - val_mse: 6.1772\n",
      "Epoch 35/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 6.8829 - mse: 6.8829 - val_loss: 5.9459 - val_mse: 5.9459\n",
      "Epoch 36/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 6.5826 - mse: 6.5826 - val_loss: 5.7392 - val_mse: 5.7392\n",
      "Epoch 37/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 6.3718 - mse: 6.3718 - val_loss: 5.4568 - val_mse: 5.4568\n",
      "Epoch 38/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 6.1117 - mse: 6.1117 - val_loss: 6.4379 - val_mse: 6.4379\n",
      "Epoch 39/100\n",
      "2235/2235 [==============================] - 27s 12ms/step - loss: 5.6810 - mse: 5.6810 - val_loss: 4.8342 - val_mse: 4.8342\n",
      "Epoch 40/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 5.1784 - mse: 5.1784 - val_loss: 4.5526 - val_mse: 4.5526\n",
      "Epoch 41/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 5.8396 - mse: 5.8396 - val_loss: 3.9156 - val_mse: 3.9156\n",
      "Epoch 42/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 4.4547 - mse: 4.4547 - val_loss: 4.0142 - val_mse: 4.0142\n",
      "Epoch 43/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 4.6380 - mse: 4.6380 - val_loss: 4.1378 - val_mse: 4.1378\n",
      "Epoch 44/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 4.0499 - mse: 4.0499 - val_loss: 3.4728 - val_mse: 3.4728\n",
      "Epoch 45/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.9929 - mse: 3.9929 - val_loss: 3.9997 - val_mse: 3.9997\n",
      "Epoch 46/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.8368 - mse: 3.8368 - val_loss: 3.2397 - val_mse: 3.2397\n",
      "Epoch 47/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 4.4354 - mse: 4.4354 - val_loss: 3.2684 - val_mse: 3.2684\n",
      "Epoch 48/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.5405 - mse: 3.5405 - val_loss: 3.2178 - val_mse: 3.2178\n",
      "Epoch 49/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.4244 - mse: 3.4244 - val_loss: 3.1100 - val_mse: 3.1100\n",
      "Epoch 50/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 3.3836 - mse: 3.3836 - val_loss: 2.6255 - val_mse: 2.6255\n",
      "Epoch 51/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.0993 - mse: 3.0993 - val_loss: 2.6173 - val_mse: 2.6173\n",
      "Epoch 52/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 3.0784 - mse: 3.0784 - val_loss: 2.7001 - val_mse: 2.7001\n",
      "Epoch 53/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.8875 - mse: 2.8875 - val_loss: 2.5890 - val_mse: 2.5890\n",
      "Epoch 54/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.8149 - mse: 2.8149 - val_loss: 2.9843 - val_mse: 2.9843\n",
      "Epoch 55/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.7230 - mse: 2.7230 - val_loss: 2.4353 - val_mse: 2.4353\n",
      "Epoch 56/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.6202 - mse: 2.6202 - val_loss: 2.2021 - val_mse: 2.2021\n",
      "Epoch 57/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 2.5703 - mse: 2.5703 - val_loss: 2.0568 - val_mse: 2.0568\n",
      "Epoch 58/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.4488 - mse: 2.4488 - val_loss: 2.1007 - val_mse: 2.1007\n",
      "Epoch 59/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.4851 - mse: 2.4851 - val_loss: 2.5925 - val_mse: 2.5925\n",
      "Epoch 60/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.3051 - mse: 2.3051 - val_loss: 2.0250 - val_mse: 2.0250\n",
      "Epoch 61/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.2774 - mse: 2.2774 - val_loss: 1.8678 - val_mse: 1.8678\n",
      "Epoch 62/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.1964 - mse: 2.1964 - val_loss: 1.6412 - val_mse: 1.6412\n",
      "Epoch 63/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 2.1172 - mse: 2.1172 - val_loss: 1.5474 - val_mse: 1.5474\n",
      "Epoch 64/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 2.0530 - mse: 2.0530 - val_loss: 1.5765 - val_mse: 1.5765\n",
      "Epoch 65/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 2.0548 - mse: 2.0548 - val_loss: 1.6562 - val_mse: 1.6562\n",
      "Epoch 66/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 1.9261 - mse: 1.9261 - val_loss: 1.4926 - val_mse: 1.4926\n",
      "Epoch 67/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.9032 - mse: 1.9032 - val_loss: 1.6465 - val_mse: 1.6465\n",
      "Epoch 68/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.8990 - mse: 1.8990 - val_loss: 1.4054 - val_mse: 1.4054\n",
      "Epoch 69/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.8086 - mse: 1.8086 - val_loss: 1.5873 - val_mse: 1.5873\n",
      "Epoch 70/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.8273 - mse: 1.8273 - val_loss: 1.5006 - val_mse: 1.5006\n",
      "Epoch 71/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.7659 - mse: 1.7659 - val_loss: 1.4664 - val_mse: 1.4664\n",
      "Epoch 72/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.7508 - mse: 1.7508 - val_loss: 1.3282 - val_mse: 1.3282\n",
      "Epoch 73/100\n",
      "2235/2235 [==============================] - 25s 11ms/step - loss: 1.7781 - mse: 1.7781 - val_loss: 1.3589 - val_mse: 1.3589\n",
      "Epoch 74/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 1.7122 - mse: 1.7122 - val_loss: 1.5566 - val_mse: 1.5566\n",
      "Epoch 75/100\n",
      "2235/2235 [==============================] - 26s 11ms/step - loss: 1.7219 - mse: 1.7219 - val_loss: 1.5048 - val_mse: 1.5048\n",
      "Epoch 76/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 1.6595 - mse: 1.6595 - val_loss: 2.2662 - val_mse: 2.2662\n",
      "Epoch 77/100\n",
      "2235/2235 [==============================] - 26s 12ms/step - loss: 1.6708 - mse: 1.6708 - val_loss: 1.5736 - val_mse: 1.5736\n",
      "559/559 [==============================] - 2s 2ms/step\n",
      "Mean Squared Error (MSE) for Best Model: 1.3281829683661643\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import kerastuner as kt\n",
    "\n",
    "# Define a function to build the LSTM model with hyperparameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32),\n",
    "                   activation=hp.Choice('activation', values=['relu', 'tanh']),\n",
    "                   return_sequences=True,\n",
    "                   input_shape=(1, X_train_scaled.shape[1])))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "                   activation=hp.Choice('activation', values=['relu', 'tanh'])))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Define the tuner and search space\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Number of trials to run\n",
    "    directory='my_tuning_directory',  # Directory to save results\n",
    "    project_name='my_lstm_tuning'  # Name for this tuning project\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train_reshaped, y_train, epochs=50, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train_reshaped, y_train, epochs=100, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE) for Best Model:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TANK1:\n",
      "R-squared: 0.9963211225424352\n",
      "Mean Absolute Error: 0.5228424342153323\n",
      "Root Mean Squared Error: 1.1524682070956076\n",
      "Mean Squared Error: 1.3281829683661643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"TANK1:\")\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MG\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model with the desired name\n",
    "model.save(\"Final_Tank1_lstmModel.h5\")\n",
    "model.save(\"Final_Tank1_lstmModel.keras\")\n",
    "# Load the saved model\n",
    "from tensorflow import keras\n",
    "\n",
    "loaded_model = keras.models.load_model(\"Tank1_lstmModel.h5\")\n",
    "\n",
    "# You can then use loaded_model for predictions or further training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
